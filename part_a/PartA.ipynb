{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "def _load_csv(path):\n",
    "    # A helper function to load the csv file.\n",
    "    if not os.path.exists(path):\n",
    "        raise Exception(\"The specified path {} does not exist.\".format(path))\n",
    "    # Initialize the data.\n",
    "    data = {\n",
    "        \"user_id\": [],\n",
    "        \"question_id\": [],\n",
    "        \"is_correct\": []\n",
    "    }\n",
    "    # Iterate over the row to fill in the data.\n",
    "    with open(path, \"r\") as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                data[\"question_id\"].append(int(row[0]))\n",
    "                data[\"user_id\"].append(int(row[1]))\n",
    "                data[\"is_correct\"].append(int(row[2]))\n",
    "            except ValueError:\n",
    "                # Pass first row.\n",
    "                pass\n",
    "            except IndexError:\n",
    "                # is_correct might not be available.\n",
    "                pass\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_train_sparse(root_dir=\"/data\"):\n",
    "    \"\"\" Load the training data as a spare matrix representation.\n",
    "\n",
    "    :param root_dir: str\n",
    "    :return: 2D sparse matrix\n",
    "    \"\"\"\n",
    "    path = os.path.join(root_dir, \"train_sparse.npz\")\n",
    "    if not os.path.exists(path):\n",
    "        raise Exception(\"The specified path {} \"\n",
    "                        \"does not exist.\".format(os.path.abspath(path)))\n",
    "    matrix = load_npz(path)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def load_train_csv(root_dir=\"/data\"):\n",
    "    \"\"\" Load the training data as a dictionary.\n",
    "\n",
    "    :param root_dir: str\n",
    "    :return: A dictionary {user_id: list, question_id: list, is_correct: list}\n",
    "        WHERE\n",
    "        user_id: a list of user id.\n",
    "        question_id: a list of question id.\n",
    "        is_correct: a list of binary value indicating the correctness of\n",
    "        (user_id, question_id) pair.\n",
    "    \"\"\"\n",
    "    path = os.path.join(root_dir, \"train_data.csv\")\n",
    "    return _load_csv(path)\n",
    "\n",
    "\n",
    "def load_valid_csv(root_dir=\"/data\"):\n",
    "    \"\"\" Load the validation data as a dictionary.\n",
    "\n",
    "    :param root_dir: str\n",
    "    :return: A dictionary {user_id: list, question_id: list, is_correct: list}\n",
    "        WHERE\n",
    "        user_id: a list of user id.\n",
    "        question_id: a list of question id.\n",
    "        is_correct: a list of binary value indicating the correctness of\n",
    "        (user_id, question_id) pair.\n",
    "    \"\"\"\n",
    "    path = os.path.join(root_dir, \"valid_data.csv\")\n",
    "    return _load_csv(path)\n",
    "\n",
    "\n",
    "def load_public_test_csv(root_dir=\"/data\"):\n",
    "    \"\"\" Load the test data as a dictionary.\n",
    "\n",
    "    :param root_dir: str\n",
    "    :return: A dictionary {user_id: list, question_id: list, is_correct: list}\n",
    "        WHERE\n",
    "        user_id: a list of user id.\n",
    "        question_id: a list of question id.\n",
    "        is_correct: a list of binary value indicating the correctness of\n",
    "        (user_id, question_id) pair.\n",
    "    \"\"\"\n",
    "    path = os.path.join(root_dir, \"test_data.csv\")\n",
    "    return _load_csv(path)\n",
    "\n",
    "\n",
    "def load_private_test_csv(root_dir=\"/data\"):\n",
    "    \"\"\" Load the private test data as a dictionary.\n",
    "\n",
    "    :param root_dir: str\n",
    "    :return: A dictionary {user_id: list, question_id: list, is_correct: list}\n",
    "        WHERE\n",
    "        user_id: a list of user id.\n",
    "        question_id: a list of question id.\n",
    "        is_correct: an empty list.\n",
    "    \"\"\"\n",
    "    path = os.path.join(root_dir, \"private_test_data.csv\")\n",
    "    return _load_csv(path)\n",
    "\n",
    "\n",
    "def save_private_test_csv(data, file_name=\"private_test_result.csv\"):\n",
    "    \"\"\" Save the private test data as a csv file.\n",
    "\n",
    "    This should be your submission file to Kaggle.\n",
    "    :param data: A dictionary {user_id: list, question_id: list, is_correct: list}\n",
    "        WHERE\n",
    "        user_id: a list of user id.\n",
    "        question_id: a list of question id.\n",
    "        is_correct: a list of binary value indicating the correctness of\n",
    "        (user_id, question_id) pair.\n",
    "    :param file_name: str\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if not isinstance(data, dict):\n",
    "        raise Exception(\"Data must be a dictionary.\")\n",
    "    cur_id = 1\n",
    "    valid_id = [\"0\", \"1\"]\n",
    "    with open(file_name, \"w\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([\"id\", \"is_correct\"])\n",
    "        for i in range(len(data[\"user_id\"])):\n",
    "            if str(int(data[\"is_correct\"][i])) not in valid_id:\n",
    "                raise Exception(\"Your data['is_correct'] is not in a valid format.\")\n",
    "            writer.writerow([str(cur_id), str(int(data[\"is_correct\"][i]))])\n",
    "            cur_id += 1\n",
    "    return\n",
    "\n",
    "\n",
    "def evaluate(data, predictions, threshold=0.5):\n",
    "    \"\"\" Return the accuracy of the predictions given the data.\n",
    "\n",
    "    :param data: A dictionary {user_id: list, question_id: list, is_correct: list}\n",
    "    :param predictions: list\n",
    "    :param threshold: float\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    if len(data[\"is_correct\"]) != len(predictions):\n",
    "        raise Exception(\"Mismatch of dimensions between data and prediction.\")\n",
    "    if isinstance(predictions, list):\n",
    "        predictions = np.array(predictions).astype(np.float64)\n",
    "    return (np.sum((predictions >= threshold) == data[\"is_correct\"])\n",
    "            / float(len(data[\"is_correct\"])))\n",
    "\n",
    "\n",
    "def sparse_matrix_evaluate(data, matrix, threshold=0.5):\n",
    "    \"\"\" Given the sparse matrix represent, return the accuracy of the prediction on data.\n",
    "\n",
    "    :param data: A dictionary {user_id: list, question_id: list, is_correct: list}\n",
    "    :param matrix: 2D matrix\n",
    "    :param threshold: float\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    total_prediction = 0\n",
    "    total_accurate = 0\n",
    "    for i in range(len(data[\"is_correct\"])):\n",
    "        cur_user_id = data[\"user_id\"][i]\n",
    "        cur_question_id = data[\"question_id\"][i]\n",
    "        if matrix[cur_user_id, cur_question_id] >= threshold and data[\"is_correct\"][i]:\n",
    "            total_accurate += 1\n",
    "        if matrix[cur_user_id, cur_question_id] < threshold and not data[\"is_correct\"][i]:\n",
    "            total_accurate += 1\n",
    "        total_prediction += 1\n",
    "    return total_accurate / float(total_prediction)\n",
    "\n",
    "\n",
    "def sparse_matrix_predictions(data, matrix, threshold=0.5):\n",
    "    \"\"\" Given the sparse matrix represent, return the predictions.\n",
    "\n",
    "    This function can be used for submitting Kaggle competition.\n",
    "\n",
    "    :param data: A dictionary {user_id: list, question_id: list, is_correct: list}\n",
    "    :param matrix: 2D matrix\n",
    "    :param threshold: float\n",
    "    :return: list\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for i in range(len(data[\"user_id\"])):\n",
    "        cur_user_id = data[\"user_id\"][i]\n",
    "        cur_question_id = data[\"question_id\"][i]\n",
    "        if matrix[cur_user_id, cur_question_id] >= threshold:\n",
    "            predictions.append(1.)\n",
    "        else:\n",
    "            predictions.append(0.)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_train_csv(\"../data\")\n",
    "val_data = load_valid_csv(\"../data\")\n",
    "test_data = load_public_test_csv(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([488, 355, 123, ...,  49, 308, 514])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_data['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_idx(data, matrix, num_resamples):\n",
    "    resampled_data = []\n",
    "    resampled_matrix = []\n",
    "    \n",
    "    for idx in range(num_resamples):\n",
    "        random_idx = np.random.randint(0, len(matrix), len(matrix))\n",
    "        random_idx = np.arange(0, len(matrix))\n",
    "        sampled_dict = {}\n",
    "        sampled_dict['user_id'] = list(np.array(data['user_id'])[random_idx])\n",
    "        sampled_dict['question_id'] = list(np.array(data['question_id'])[random_idx])\n",
    "        sampled_dict['is_correct'] = list(np.array(data['is_correct'])[random_idx])\n",
    "        resampled_data.append(sampled_dict)\n",
    "        resampled_matrix.append(matrix[random_idx])\n",
    "    return resampled_data, resampled_matrix\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[510  53 326 294 214 130  31  43 273 476 309 251  92  96  51 371 305 453\n",
      " 172  21 502  91 343  77  61 108 167 191 382 403 335 142 201 502 157 431\n",
      " 273 377 244 540 231 424 402   3 155  95 401 425 333  78  49 540 183 314\n",
      " 360  56 504 473 189 370 229 196 466 143 353 528   1  97 141 183 192 372\n",
      " 532 424 417 106 220 117 151 331 194  57 302 172 295 131 155 342 269  89\n",
      " 432 224 359   6 124  26 280 243 379 256 374 361 198 253  25  88 454 287\n",
      " 312 521 105 427 109 524 138 134 528 158 455 269 161 186 169 318 153 491\n",
      " 405 413 283 239  82  14   5 111 456 418 311 394 161 264 101 323  72 135\n",
      "  62 152 534 396 499 318 138 187 112 473 290   6 466 284 276   2 507 206\n",
      " 106 453  51  93 321 538 339 258 337 129  93 450 507 215 239   8 149 333\n",
      " 509 243 441  38 282  43 424 220 125 475 234  64 320 311 151 197 540 222\n",
      " 240 225 160  87 191 119 279 509 152 501 231 120  20 428  29 191 318 196\n",
      " 152 502  10 102 482 304 444   9  25 356  48  15 347  54 122 305 224  29\n",
      " 483  29 155 100 270 301 298 536 503 334 297 204  94  86  91 334  83 380\n",
      " 103 299 491 515 133 357 249 261  95 278  69 331  47 153 147 289 346  43\n",
      " 536  47  51 519 475  41 178  42  78 512 210  27  48 172 460 195  18 478\n",
      " 177 272 141 329 241 278 463 329 141 139  31 181 200 428 289 226  46  44\n",
      " 184  44  46  19  96  31 326   1 229  63 181 204 214 231 296 475 494 111\n",
      "  67 121 102 186 344 155 159 251 522 514 388 516 237 509   7  88 217 358\n",
      " 162 277 252  43  37 109 181 337 344 215 313 158 497 311 385  11  84  10\n",
      " 164 134 102 368 200 141 519 290 487 123 366 334 140 198 268 166 470 541\n",
      " 453 105 137 360  34 187 266 262 216 524 108 400 196 421 470  18  80  13\n",
      " 486 322 370 446  46 139 365 208 184 415  56 480 533 206 313 520 366  75\n",
      " 439  40  92 252 251 213  56 153 330 404  27 336  54  65 143 275 395 478\n",
      " 318 336 299 284 259 208 497 374  48 290 463 333  86  53  43 502 391 116\n",
      " 487 460 517 199 115 124  69 213 466  40 407 516  30 366 503  64 480 514\n",
      " 199 181 437  42 340  49  37 496 135 321 261 509 491 285 175 474 171 294\n",
      " 486  73 124 426 506 433 185 502  50 214 414 388 353 344 459 151 332 352\n",
      " 156 452 322 459 169  36  24  60  14  76  49 468  14 180 424  69 120 446\n",
      " 310 389 357 147 482 394 321 179 470 156 306 134 503 363 239 355 529 317\n",
      " 399 252]\n",
      "[235 219 384  91 317 359 476  80 136  77 208 531  93 529 443 349 474 276\n",
      "  72 164 170  64  41 355 467 485   8 356  30 140  67 127 493 225 533 534\n",
      " 161 495  23 194 430 232 194 348  20 523 125 262 202 112 286  44 396 457\n",
      " 243 178   8 473  70 331  24  89 376 323 104 162  56 101 370 192 367 334\n",
      " 338 446 326 276 163 446   8  36 352 396 208 528 134  84  64 247 327 497\n",
      "  78 181 283  28 448  10 526 420 292  35 489 451 112 211 384 430 461  22\n",
      " 234  32 366  11 466 393 216 300 331  54   7  72  46 451 362 178 323 111\n",
      " 341 229 284 302 206 144 332 463  94 303 430 407 358 143 142 167 343 418\n",
      " 306 208 240 276 331 482 234 124 213 514 449 435  30  76 266   6 536 132\n",
      " 190 188 129 402 274 480 293 264 190 269 520 395 473 443  77 137 112 228\n",
      " 233 213 325 222 225 469 406 206  82 441 489 363 233 400 518 275 416 536\n",
      " 349 484 148 198 216 276 291 348 353 158 290 432 238 218 419 198 351 379\n",
      "   7  55 117 440 185 160 220 124 128 432 393  55 358 240 218 221 402 521\n",
      "  74  72   6 416 135 316 164  87 360 494 207 502 193 256 126 362 349  26\n",
      "   4 272 205 273   7 299 134  10 112 458 295 302 152 541  15 356 356  93\n",
      " 438  74 517 388 476 200 240  49 451 294 121 146 362 379 249 348 288 500\n",
      " 448 178 505 298 368 417 178 390 126 266 242 229  11  91 541 411 299 257\n",
      " 296 384 439 451 522 263 323 351 216 464  72 255  55  10 114 280  46  89\n",
      " 195 455 386  30 417 268 362 264 231 136 304 522 337 176 194 465  84 497\n",
      " 149 213 415 536 368 150 407 162 263  46 121  56  80 384 440 451 324 490\n",
      "  55 276 236 259 420 352 311 252 173  35 490 362 121 292 443 314 128 376\n",
      "  42 474 517 498  44 470  47 460 370 143  75 323 210 446 124  82 540  22\n",
      " 145 391  34  96 454 463 137 451 283 130 205 122 333 489  47 139 305  59\n",
      "  44  81 419 257 132 219 176 500  18 354 371 146 535 103 499 529 375  71\n",
      " 536 160 280 263 183 494  24 434 501 456  95  59 376 414  76 429 344 295\n",
      "   9  70 102 502 282 510 399 203 244 347 456 202 398 446 310 460 508 445\n",
      " 278 517  40 414 278 340 160 302 173 510 380 375  59  61 337 154 341 503\n",
      " 378 129  45 425  49 161 244 402 399 363 316 508 518 509 182  73 155 535\n",
      " 366 298 299 485 363  77  82 406 519   0 436 211 431 500  97  82 101 208\n",
      " 137  55 108 516 357 506 322 462 246 340 259  55 388 225 403 488 204 316\n",
      " 184 270]\n",
      "[ 95  63 323  91 466  57 342 176 284 527 154 379 433 404 533 368 107 531\n",
      "  67 292 136 151  66 347  43 445 491  36 324 216  29 165 497 525 213 250\n",
      " 169 357 345 237 495 106 319 140 460  49 343 293 202 370 126 201 305 305\n",
      "  16 395 120 478 285 303  70  71 446  45 165  80 294  98 533 207 300 514\n",
      " 288  83 361 474 206 379 346 303 132 296 538 472 296 279 480  43 213 116\n",
      " 382  67 226 239 363 375  97 323 256 432 460 401 309 112 119 169 191 199\n",
      " 445 274 436 223 302 505 429 438 212 200  35 257 461 305 260 151 205   2\n",
      "  77 370  63 502   9 339 476 139 160  21 305 414 315 380 327 416 116 411\n",
      " 141 242   4 256 100 425 288 155 402 226 283 187 498 266  64 513 329 472\n",
      " 280 319 517 541 272 261 224 379 305 154 113 411 339  27 220 253  91 224\n",
      " 425  20 235 101 399 322 287 327 326 100 281 318 436 375 352 479  38 453\n",
      " 132 443 181 153 473 412 253 423 224 348 227 281 488 353 144  26 511 129\n",
      "  44 487 391 258 263 336 539 499 450  19 184  41 217 525 411 214 339 112\n",
      " 333 262 185 167 200 419 223 300 166  69 508 500 304 523 146  48 242  64\n",
      " 319 498 271 415 351 261 237 120  10 113 386 394 290 105 469 466  22  81\n",
      " 242 441 520 325 261 394 320 211 343 298 268 228 226   1 173 524 539 163\n",
      " 137 344 146  10 319 283 345  63 129 461 330 342 426 345 313 396 487  89\n",
      " 275 109  43 306 173 251 157 156 133 275 110 244  32 181 283 429  29 393\n",
      " 390 198 251 240 303 271 383 458 514 242 315  35 323  80 115 111 444 398\n",
      " 293 477 133 470 317 500 201 161  79 303 392  58 428  88  66 417 215 253\n",
      " 124 488  85 455 273 467 531   2 430 234 523  59 312 480 248  84 151 441\n",
      " 308 505 279   5 104 155 269 292 205  55  83 467 208  17 184 354 441 158\n",
      " 490 135  23 334 123 334  95 381 132 503 174 536 211 373  43 447 306 200\n",
      "  82  60 160 429 433 378 453 520 113 127  75  40  54 174 299 189  29 258\n",
      " 489 492  92 192 367 392 162 359 178 219 500 159 428 219 302 201 501 478\n",
      " 539 144 439 349 371 487 361 328 305 142 298  57 417 216 381 396  40 273\n",
      " 233  35  17 312 529 360 504 304 430 110  73 206 116 396 290 137 150 104\n",
      " 504 283  73 191 190 170  19  28 204 338 236 499 249 287 156 231 265 472\n",
      " 161 185 477 246  56 271  63 528 439 199 264 417 459 118 520  24 112 524\n",
      " 516 322 179  75 277 454 277  16 417 447 469 393 258 364 196 409 518  93\n",
      " 236 161]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = bootstrap_idx(train_data, sparse_matrix, 3)\n",
    "b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import KNNImputer\n",
    "# from utils import *\n",
    "\n",
    "\n",
    "def knn_impute_by_user(matrix, valid_data, k):\n",
    "    \"\"\" Fill in the missing values using k-Nearest Neighbors based on\n",
    "    student similarity. Return the accuracy on valid_data.\n",
    "\n",
    "    See https://scikit-learn.org/stable/modules/generated/sklearn.\n",
    "    impute.KNNImputer.html for details.\n",
    "\n",
    "    :param matrix: 2D sparse matrix\n",
    "    :param valid_data: A dictionary {user_id: list, question_id: list,\n",
    "    is_correct: list}\n",
    "    :param k: int\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    nbrs = KNNImputer(n_neighbors=k)\n",
    "    # We use NaN-Euclidean distance measure.\n",
    "    mat = nbrs.fit_transform(matrix)\n",
    "    acc = sparse_matrix_evaluate(valid_data, mat)\n",
    "    # print(\"Validation Accuracy: {}\".format(acc))\n",
    "    return acc\n",
    "\n",
    "\n",
    "def knn_impute_by_item(matrix, valid_data, k):\n",
    "    \"\"\" Fill in the missing values using k-Nearest Neighbors based on\n",
    "    question similarity. Return the accuracy on valid_data.\n",
    "\n",
    "    :param matrix: 2D sparse matrix\n",
    "    :param valid_data: A dictionary {user_id: list, question_id: list,\n",
    "    is_correct: list}\n",
    "    :param k: int\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    #####################################################################\n",
    "    # TODO:                                                             #\n",
    "    # Implement the function as described in the docstring.             #\n",
    "    #####################################################################\n",
    "    nbrs = KNNImputer(n_neighbors=k)\n",
    "    # We use NaN-Euclidean distance measure.\n",
    "    mat = nbrs.fit_transform(matrix.T).T\n",
    "    acc = sparse_matrix_evaluate(valid_data, mat)\n",
    "    # print(\"Validation Accuracy: {}\".format(acc))\n",
    "    #####################################################################\n",
    "    #                       END OF YOUR CODE                            #\n",
    "    #####################################################################\n",
    "    return acc\n",
    "\n",
    "\n",
    "def plot_accuracy(k_list, acc, filename, title):\n",
    "    plt.plot(k_list, acc)\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.xticks(k_list)\n",
    "    plt.grid(axis='x', color='0.95')\n",
    "    plt.title(title)\n",
    "    plt.savefig(\"../figs/\" + filename + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    sparse_matrix = load_train_sparse(\"../data\").toarray()\n",
    "    val_data = load_valid_csv(\"../data\")\n",
    "    test_data = load_public_test_csv(\"../data\")\n",
    "\n",
    "    print(\"Sparse matrix:\")\n",
    "    print(sparse_matrix)\n",
    "    print(\"Shape of sparse matrix:\")\n",
    "    print(sparse_matrix.shape)\n",
    "\n",
    "    #####################################################################\n",
    "    # TODO:                                                             #\n",
    "    # Compute the validation accuracy for each k. Then pick k* with     #\n",
    "    # the best performance and report the test accuracy with the        #\n",
    "    # chosen k*.                                                        #\n",
    "    #####################################################################\n",
    "\n",
    "    k_list = [1, 6, 11, 16, 21, 26]\n",
    "    train_acc_by_user, val_acc_by_item = [], []\n",
    "\n",
    "    for k in k_list:\n",
    "        print(\"K: \" + str(k))\n",
    "\n",
    "        res = knn_impute_by_user(sparse_matrix, val_data, k)\n",
    "        print(\"User based collaborative filtering: \" + str(res))\n",
    "        train_acc_by_user.append(res)\n",
    "\n",
    "        res = knn_impute_by_item(sparse_matrix, val_data, k)\n",
    "        print(\"Item based collaborative filtering: \" + str(res))\n",
    "        val_acc_by_item.append(res)\n",
    "\n",
    "    plot_accuracy(k_list, train_acc_by_user, \"Q1a\", \"User based validation accuracy\")\n",
    "    plot_accuracy(k_list, val_acc_by_item, \"Q1c\", \"Item based validation accuracy\")\n",
    "\n",
    "    # Final test accuracy\n",
    "    best_k = 11\n",
    "    print(knn_impute_by_user(sparse_matrix, test_data, best_k))\n",
    "\n",
    "    best_k = 21\n",
    "    print(knn_impute_by_item(sparse_matrix, test_data, best_k))\n",
    "\n",
    "    #####################################################################\n",
    "    #                       END OF YOUR CODE                            #\n",
    "    #####################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "nbrs = KNNImputer(n_neighbors=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nbrs.fit_transform(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "non_null_idx = np.argwhere(np.isnan(sparse_matrix[i, :]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1000.        ,   1274.2749857 ,   1623.77673919,   2069.13808111,\n",
       "         2636.65089873,   3359.81828628,   4281.33239872,   5455.59478117,\n",
       "         6951.92796178,   8858.6679041 ,  11288.37891685,  14384.49888288,\n",
       "        18329.80710832,  23357.2146909 ,  29763.51441631,  37926.90190732,\n",
       "        48329.30238572,  61584.8211066 ,  78475.99703515, 100000.        ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2       , 0.8       , 0.6       , ..., 0.4       , 0.6       ,\n",
       "        0.4       ],\n",
       "       [0.4       , 0.        , 0.4       , ..., 0.4       , 0.6       ,\n",
       "        0.6       ],\n",
       "       [0.4       , 0.8       , 1.        , ..., 0.4       , 0.6       ,\n",
       "        0.8       ],\n",
       "       ...,\n",
       "       [0.8       , 0.53846154, 0.4       , ..., 0.2       , 0.8       ,\n",
       "        0.5       ],\n",
       "       [0.4       , 0.6       , 0.4       , ..., 0.2       , 0.6       ,\n",
       "        0.8       ],\n",
       "       [0.2       , 0.4       , 0.4       , ..., 0.45454545, 0.6       ,\n",
       "        0.2       ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  3,  4,  6,  8, 13, 14, 15, 16, 18, 21, 24, 25, 26, 29, 30, 33,\n",
       "        36, 38, 40, 41, 42, 45, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 61,\n",
       "        62, 64, 65, 66, 67, 69, 70, 73, 76, 77, 79, 80, 82, 83, 84, 85, 86,\n",
       "        88, 90, 91, 92, 93, 94, 95, 97, 99]),\n",
       " array([2, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 4, 4, 1, 1, 1, 3, 1, 2, 1,\n",
       "        1, 3, 1, 2, 1, 1, 3, 2, 1, 1, 2, 3, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2,\n",
       "        2, 2, 2, 1, 1, 3, 1, 1, 1, 2, 2, 3, 1, 2, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.random.randint(1, 100, 100), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 542, 1774)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(sparse_matrix, 3, axis=0).reshape(3, sparse_matrix.shape[0], sparse_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_idx(data, num_resamples):\n",
    "    idx = np.random.randint(0, len(data), (num_resamples, len(data)))\n",
    "    return idx, data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, d = bootstrap_idx(sparse_matrix, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(sparse_matrix[395], d[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan,  0., nan, ..., nan, nan, nan],\n",
       "       [nan, nan,  1., ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.concatenate([train_matrix, train_matrix, train_matrix]).reshape(3, len(train_matrix), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[2, 3, 4] == np.array([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., nan, nan, ..., nan, nan, nan])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix[373]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bootstrap_idx(data, matrix, num_resamples):\n",
    "    resampled_data = []\n",
    "    resampled_matrix = []\n",
    "\n",
    "    for idx in range(num_resamples):\n",
    "        random_idx = np.random.randint(0, len(matrix), len(matrix))\n",
    "        random_idx = np.arange(0, len(matrix))\n",
    "        # if idx == 0:\n",
    "        #     random_idx = np.repeat(np.arange(0, len(matrix)//2), 2)\n",
    "        # elif idx == 1:\n",
    "        #     random_idx = np.repeat(np.arange(len(matrix//2), len(matrix)), 2)\n",
    "        sampled_dict = {}\n",
    "        sampled_dict['user_id'] = list(np.array(data['user_id'])[random_idx])\n",
    "        sampled_dict['question_id'] = list(np.array(data['question_id'])[random_idx])\n",
    "        sampled_dict['is_correct'] = list(np.array(data['is_correct'])[random_idx])\n",
    "        resampled_data.append(sampled_dict)\n",
    "        resampled_matrix.append(matrix[random_idx])\n",
    "    return resampled_data, resampled_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = bootstrap_idx(train_data, sparse_matrix, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3):\n",
    "    for i in range(len(x[j][\"user_id\"])):\n",
    "        cur_user_id = x[j][\"user_id\"][i]\n",
    "        cur_question_id = x[j][\"question_id\"][i]\n",
    "        if x[j][\"is_correct\"][i] != y[j][cur_user_id, cur_question_id]:\n",
    "            print(x[j][\"is_correct\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56688\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[\"user_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "        260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "        273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "        286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "        299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "        325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "        377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "        390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "        403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "        416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "        429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "        442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "        455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "        468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
       "        481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
       "        494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
       "        507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
       "        520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
       "        533, 534, 535, 536, 537, 538, 539, 540, 541]),\n",
       " array([305,  52, 206, 201,  83,  55, 432,  18,  18,  86,  34, 171, 379,\n",
       "         39,  62,  19,  26, 248, 129, 266,  46,  72,  22, 137, 237,  29,\n",
       "         41, 280,  24,  28, 170,  42, 193,  31,  35,  28, 419,  65,  57,\n",
       "         80, 283, 332, 260,  25, 315,  34,  94, 411,  92, 420, 318, 269,\n",
       "        211,  33, 252, 124, 113, 270, 132, 103,  37,  79, 127,  62, 113,\n",
       "        268, 179,  23, 389,  20, 307,  18,  37, 184,  31,  47,  38, 311,\n",
       "         42,  45,  69, 153, 158,  93,  39,  20,  60,  19,  79,  31, 139,\n",
       "         23,  18,  88,  25, 165,  66,  86, 233,  95, 213, 309, 134, 100,\n",
       "        386, 200, 266,  16,  30,  17, 102, 123,  22, 197,  62, 259, 193,\n",
       "         23, 142,  69, 450,  35,  47, 189,  44,  24,  53, 193, 177, 233,\n",
       "         28, 206,  18,  49, 231,  93, 122,  18,  71,  40,  24,  28,  32,\n",
       "        147, 363,  20,  54, 108, 240, 220, 187, 284, 127, 199, 373, 167,\n",
       "         62, 449,  20,  46,  64, 108,  52, 456,  65, 141,  23,  33, 127,\n",
       "         83,  81,  23, 110, 105, 111, 124,  46,  42, 166,  22, 138,  80,\n",
       "         33,  39,  16, 218, 439, 248, 151, 407, 177, 113,  43, 183, 171,\n",
       "        106,  70, 178, 148, 163,  20, 165,  73, 156, 128,  27,  65, 167,\n",
       "         39,  14, 194, 283, 451, 320, 194,  36, 226,  36, 341,  80,  36,\n",
       "        520, 102, 333, 137, 303, 326, 285, 261,  36,  97, 418,  67,  78,\n",
       "        165,  64, 222, 227,  15, 219, 252,  96, 277, 188, 185, 123, 140,\n",
       "         25, 155,  38, 162, 277,  19,  38,  88, 293, 199, 350, 436, 112,\n",
       "         88,  24, 275, 380, 183, 165,  66,  25, 293, 122,  69, 136,  48,\n",
       "         43, 226, 299,  38,  25,  79, 148,  85, 356,  86, 307, 344,  27,\n",
       "         24, 216,  20,  33, 373, 435, 106, 224, 115, 190, 142, 165,  20,\n",
       "        305, 460, 424,  19,  57, 120, 119,  30,  81, 185,  44,  36, 246,\n",
       "         78,  25,  75,  16,  24,  36, 148,  33,  33,  82,  77,  32,  69,\n",
       "         28,  48,  22,  25,  44, 311,  31, 241,  42,  21,  47,  97,  23,\n",
       "         30, 161,  59,  34,  43,  43, 192, 280, 338,  39,  88,  39,  63,\n",
       "        141,  66, 199, 154,  35, 119,  18,  38,  78,  18,  48,  70,  69,\n",
       "         41,  22,  29, 184,  52,  38,  19,  16,  19, 285,  57,  14,  90,\n",
       "         19,  24,  46,  48,  35, 226,  21,  48,  48,  25,  32,  20,  72,\n",
       "         50, 125,  26,  21,  48, 102,  64,  80,  43,  33,  27,  33,  23,\n",
       "         32,  74,  29,  23,  34,  39,  50, 101,  27,  28,  22, 106, 176,\n",
       "         38,  21,  46, 130,  12,  29,  29,  17,  34, 135,  59,  43,  59,\n",
       "         51,  74,  37,  31,  71,  33,  24,  76,  22,  54,  48, 121,  15,\n",
       "         55,  57, 122,  37,  28,  23,  63,  21,  70,  48,  37,  23,  39,\n",
       "         52,  29,  57,  21,  31,  59,  25,  22,  36,  29,  25,  20,  74,\n",
       "         28,  22,  79,  29, 100,  26,  57,  49,  27,  32,  26,  22,  21,\n",
       "         16,  44,  45,  36,  26,  22,  64,  24,  56,  32,  30,  30,  27,\n",
       "         22,  20,  44,  25,  17,  47,  25,  40,  33,  29,  79,  23,  27,\n",
       "         24,  23,  15,  25,  22,  26,  12,  50,  18,  51,  26,  29,  17,\n",
       "         27,  14,  22,  46,  19,  38,  15,  18,  22,  26,  22,  44,  27,\n",
       "         17,  20,  17,  22,  26,  19,  19,  13,  14], dtype=int64))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(train_data[\"user_id\"]), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "theta = np.random.rand(sparse_matrix.shape[0], 1)\n",
    "beta = np.random.rand(sparse_matrix.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_theta_beta_2(data, lr, theta, beta):\n",
    "    \"\"\" Update theta and beta using gradient descent.\n",
    "\n",
    "    You are using alternating gradient descent. Your update should look:\n",
    "    for i in iterations ...\n",
    "        theta <- new_theta\n",
    "        beta <- new_beta\n",
    "\n",
    "    You may optionally replace the function arguments to receive a matrix.\n",
    "\n",
    "    :param data: A dictionary {user_id: list, question_id: list,\n",
    "    is_correct: list}\n",
    "    :param lr: float\n",
    "    :param theta: Vector\n",
    "    :param beta: Vector\n",
    "    :return: tuple of vectors\n",
    "    \"\"\"\n",
    "    #####################################################################\n",
    "    # TODO:                                                             #\n",
    "    # Implement the function as described in the docstring.             #\n",
    "    #####################################################################\n",
    "    # temp = (data == 1).astype(int)\n",
    "    for i in range(len(theta)):\n",
    "        non_null_idx = np.where(~np.isnan(data[i, :]))[0]\n",
    "        temp = sigmoid(theta[i] - beta)\n",
    "\n",
    "        # print(data[i, :].shape)\n",
    "        # print(temp.shape)\n",
    "        # print(temp[non_null_idx].shape)\n",
    "        # print(non_null_idx.shape)\n",
    "        theta[i] += lr * (np.sum(data[i, :][non_null_idx]) - np.sum(temp[non_null_idx]))\n",
    "\n",
    "    for j in range(len(beta)):\n",
    "        non_null_idx = np.where(~np.isnan(data[:, j]))[0]\n",
    "        temp = sigmoid(theta - beta[j])\n",
    "        beta[j] += lr * (-np.sum(data[:, j][non_null_idx]) + np.sum(temp[non_null_idx]))\n",
    "\n",
    "    #####################################################################\n",
    "    #                       END OF YOUR CODE                            #\n",
    "    #####################################################################\n",
    "    return theta, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_theta_beta(data, lr, theta, beta):\n",
    "    \"\"\" Update theta and beta using gradient descent.\n",
    "\n",
    "    You are using alternating gradient descent. Your update should look:\n",
    "    for i in iterations ...\n",
    "        theta <- new_theta\n",
    "        beta <- new_beta\n",
    "\n",
    "    You may optionally replace the function arguments to receive a matrix.\n",
    "\n",
    "    :param data: A dictionary {user_id: list, question_id: list,\n",
    "    is_correct: list}\n",
    "    :param lr: float\n",
    "    :param theta: Vector\n",
    "    :param beta: Vector\n",
    "    :return: tuple of vectors\n",
    "    \"\"\"\n",
    "    #####################################################################\n",
    "    # TODO:                                                             #\n",
    "    # Implement the function as described in the docstring.             #\n",
    "    #####################################################################\n",
    "    \n",
    "    u_id_arr = np.array(data[\"user_id\"])\n",
    "    q_id_arr = np.array(data[\"question_id\"])\n",
    "    c_id_arr = np.array(data[\"is_correct\"])\n",
    "\n",
    "    for i in range(len(theta)):\n",
    "        theta[i] -= lr * (np.sum(sigmoid(theta[i] - beta)[q_id_arr[u_id_arr == i]]) - np.sum(c_id_arr[u_id_arr == i]))\n",
    "\n",
    "    for j in range(len(beta)):\n",
    "        beta[j] -= lr * (np.sum(c_id_arr[q_id_arr == j]) - np.sum(sigmoid(theta - beta[j])[u_id_arr[q_id_arr == j]]))\n",
    "\n",
    "    #####################################################################\n",
    "    #                       END OF YOUR CODE                            #\n",
    "    #####################################################################\n",
    "    return theta, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data\n",
    "u_id_arr = np.array(data[\"user_id\"])\n",
    "q_id_arr = np.array(data[\"question_id\"])\n",
    "c_id_arr = np.array(data[\"is_correct\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(theta[0] - beta)[q_id_arr[u_id_arr == 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\" Apply sigmoid function.\n",
    "    \"\"\"\n",
    "    return np.exp(x) / (1 + np.exp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros(shape=(542))\n",
    "beta = np.zeros(shape=(1774))\n",
    "\n",
    "x, y = update_theta_beta(train_data, 0.01, theta, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros(shape=(542))\n",
    "beta = np.zeros(shape=(1774))\n",
    "\n",
    "z, w = update_theta_beta_2(sparse_matrix, 0.01, theta, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(w, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imputer = KNNImputer(n_neighbors=5, weights=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19292106, 0.77681885, 0.5       , ..., 0.34613912, 1.        ,\n",
       "        0.42673644],\n",
       "       [0.44157109, 0.        , 0.66666667, ..., 0.        , 0.66666667,\n",
       "        0.        ],\n",
       "       [0.        , 0.5       , 1.        , ..., 0.        , 1.        ,\n",
       "        0.8025339 ],\n",
       "       ...,\n",
       "       [1.        , 0.53846154, 1.        , ..., 0.        , 0.80667439,\n",
       "        0.5       ],\n",
       "       [0.25      , 0.6       , 0.5       , ..., 0.        , 0.        ,\n",
       "        0.8       ],\n",
       "       [0.2       , 0.4       , 0.4       , ..., 0.45454545, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_imputer.fit_transform(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56688"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc311",
   "language": "python",
   "name": "csc311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
